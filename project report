--
title: "Practical Machine Learning Course Project"
author: "Marta Vicente"
date: "7 de febrero de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## These is a project submitted during a homework assignment of Courseraâ€™s MOOC Practical Machine Learning from Johns Hopkins Bloomberg School of Public Health.

#Data
The training data for this project are available here:

[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv]

The test data are available here:

[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv]

The data for this project come from this source: [http://groupware.les.inf.puc-rio.br/har].

#Replicating Results of this Experiment

Please install packages listed below and use the same seed, To install, for instance, the caret package in R, run this command:  install.packages("caret").
To avoid reinstall, run the following command:  if("caret" %in% rownames(installed.packages()) == FALSE) {install.packages("caret")} ;

The following Libraries were used in this project, and should be loaded in working environment.


```{r}
require(rattle)
require(caret)
require(rpart)
require(rpart.plot)
require(corrplot)
require(randomForest)
require(RColorBrewer)
```

#Set Seed
Load the same seed with the following line of code:

```{r}
set.seed(12345)
```

#Load Data

Read the datafiles from URL provided in project statement and load the dataframes for training and testing datasets.

```{r}
trainLocation <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testLocation <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(url(trainLocation), na.strings=c("NA","#DIV/0!",""))
testingData <- read.csv(url(testLocation), na.strings=c("NA","#DIV/0!",""))
```
#Data Cleaning Steps

Clean the dataset and get rid of observations with missing values as well as redundant variables.

```{r}
NZV <- nearZeroVar(trainingData, saveMetrics = TRUE)
head(NZV, 20)
```

```{r}
trainingClean <- trainingData[, !NZV$nzv]
testingClean <- testingData[, !NZV$nzv]
dim(trainingClean)
dim(testingClean)
```

```{r}
unwanted_col <- grepl("^X|timestamp|user_name", names(trainingClean))
training <- trainingClean[, !unwanted_col]
testing <- testingClean[, !unwanted_col]
dim(training)
dim(testing)
```

```{r}
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(training)) == 0]
```

#Data Partitioning
Split the training set into a training data set (70%) and a validation data set (30%). Validation data set is used to conduct cross validation.

```{r}
set.seed(12345) 
inTrain <- createDataPartition(training$classe, p = 0.70, list = FALSE)
validation <- training[-inTrain, ]
training <- training[inTrain, ]
```

#Data Modelling
Decision Tree Algorithm
Use Decision Tree algorithm for predictive modeling.

```{r}
modelTree <- rpart(classe ~ ., data = training, method = "class")
prp(modelTree)
```
```{r}
predictTree <- predict(modelTree, validation, type = "class")
confusionMatrix(validation$classe, predictTree)
```
```{r}
accuracy <- postResample(predictTree, validation$classe)
ose <- 1 - as.numeric(confusionMatrix(validation$classe, predictTree)$overall[1])
```

The Estimated Accuracy of the Decision Tree Algorithm is 73.6788445% and the Estimated Out-of-Sample Error is 26.3211555%.

#Random Forest
Use Random Forest for a predictive model since it automatically selects key variables and is robust to correlated covariates & outliers in general.

```{r}
modelRF <- randomForest(classe ~. , data=training)
modelRF
```

```{r}
predictRF <- predict(modelRF, validation)
confusionMatrix(validation$classe, predictRF)
```
```{r}
accuracy <- postResample(predictRF, validation$classe)
ose <- 1 - as.numeric(confusionMatrix(validation$classe, predictRF)$overall[1])
predict(modelRF, testing[, -length(names(testing))])
```


The Estimated Accuracy of the Random Forest Algorithm is 99.4902294% and the Estimated Out-of-Sample Error is 0.5097706%. The Random forest accuracy is much better than decision tree as expected.

#Predicting Test Data Set Results
Now, we apply the Random Forest model to the testing data set downloaded from the project locations.

```{r}
predict(modelRF, testing[, -length(names(testing))])
```

#Generating Files for Assignment Submission
Function to generate files with predictions to submit for assignment.

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, col.names = FALSE)
  }
}
```

Generating the Files.

```{r}
pml_write_files(predict(modelRF, testing[, -length(names(testing))]))
```
